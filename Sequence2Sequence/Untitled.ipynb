{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "* TorchText를 이용해서 pre-Processing이 필요.\n",
    "* spacy를 이용해서 data를 tokenization함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchtext Contents\n",
    "\n",
    "#### 사용방법\n",
    "\n",
    "1. 필드지정(Create Field)\n",
    "2. 데이터 세트 만들기(Create Datasets)\n",
    "3. 단어장 생성(Build vocabulary)\n",
    "4. 데이터 로더 만들기(Create Data Loader)\n",
    "\n",
    "* 테스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requriments\n",
    "\n",
    "* \"en\" : English\n",
    "* \"de\" : German\n",
    "\n",
    "```python -m spacy download en ```\n",
    "\n",
    "```python -m spacy download de ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de,\n",
    "           init_token = '<sos>',\n",
    "           eos_token = '<eos>',\n",
    "           lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "           init_token = '<sos>',\n",
    "           eos_token = '<eos>',\n",
    "           lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7855\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 구성\n",
    "\n",
    "이 구현을 위해서는 hidden layer와 cell dimension이 Encoder와 Decoder에서 동일해야 한다.\n",
    "Seq2Seq Model에서 반드시 동일한 수의 레이어 또는 동일한 숨겨진 치수 크기가 필요하지는 않음.\n",
    "다른 수의 레이어를 갖는 것과 같은 작업을 수행 한 경우 이를 처리하는 방법을 결정 해야 한다.\n",
    "Ex) Encoder 2개와 Decoder 1개만 있는 경우, Decoder가 출력한 두 개의 Context Vector를 평균화 할 것인지, Linear Layer를 모두 통과할 것인지, 최상위 Layer의 Context Vector만 사용할 것인지 등.\n",
    "\n",
    "## 자기회기 속성\n",
    "\n",
    "Seq2Seq의 훈련 방식과 추론 방식의 차이는 근본적으로 자기 회기 autoregression(AR)라는 속성 때문에 생김. 자기 회기란 과거의 자신의 값을 참조하여 현재의 값을 추론하는 특징을 가리킴.과거에 잘못 예측 했을 경우, 시간이 지날 수록 더 큰 잘못된 예측을 할 가능성을 야기 함. 또한 과거의 결괏값에 따라 문장의 구성이 바뀔 뿐만 아니라, 예측 문장의 길이마저도 바뀔 수 있음. 학습 과정에서 이미 정답을 알고 있고, 현재 모델의 예측 값과 정답과의 차이를 통해 학습하므로, 우리는 자기 회기 속성을 유지한채 훈련 할 수 없음.\n",
    "\n",
    "## Teacher Forcing\n",
    "\n",
    "Teacher Forcing : RNN Model에서 출력을 다시 입력으로 넣는 구조에서 학습 시킬때와 예측할 때가 달라 질 수 있음, 예측을 할 때는 바로 출력을 입력으로 넣음녀 되지만, 학습을 시킬때는 뒤로 갈 수록 실제 데이터와 입력이 달라져 버리는 경우가 생김.\n",
    "학습시킬때는 실제 데이터를 입력에 넣어 주는 방법을 사용하게 되는데 이 기법을 Teacher Forcing 기법이라고 함.\n",
    "\n",
    "참조 : https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-9/05-teacher-forcing\n",
    "\n",
    "## 학습하는 동안 Teacher forcing을 사용하지 않으려면\n",
    "\n",
    "일부 환경에서는 완전한 입력-목표 시퀀스 쌍을 버퍼링 할 수 없듯이(매우 긴 시퀀스는 online 학습)이는 전체 목표 시퀀스로 접근 할 수 없기 때문에 Teacher forcing을 사용할 수 없음.\n",
    "이 경우 decoder의 예측값을 입력으로 재입력하여 학습을 실행 할 수 있음(추론)\n",
    "\n",
    "참조 : https://tykimos.github.io/2018/09/14/ten-minute_introduction_to_sequence-to-sequence_learning_in_Keras/\n",
    "\n",
    "## Teacher_forcing_ratio\n",
    "\n",
    "teacher_forcing_ratio와 같은 확률로 다음 시간 단계 동안 디코더에 대한 입력으로 true면 진실(예측값과 정답이 같으면), 다음 token을 사용, 그러나 1-teacher_forcing_ratio에서는 시퀀스의 실제 다음 토큰과 일치하지 않아도 모델이 모델의 다음 입력으로 예측 한 token을 사용함.\n",
    "\n",
    "참조 : https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to tteh decoder is the : <sos>\n",
    "        \n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # 가장 높은 예측 값을 predictions 결정\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,899,013 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언어 평가 지표 방법 : Perplexity\n",
    "\n",
    "펄플렉서티(perplexity)는 언어 모델을 평가하기 위한 내부 평가 지표입니다. 보통 줄여서 PPL이 라고 표현합니다. 왜 perplexity라는 용어를 사용했을까요? 영어에서 'perplexed'는 '헷갈리는'과 유사한 의미를 가집니다. 그러니까 여기서 PPL은 '헷갈리는 정도'로 이해합시다. PPL를 처음 배울때 다소 낯설게 느껴질 수 있는 점이 있다면, PPL은 수치가 높으면 좋은 성능을 의미하는 것이 아니라, '낮을수록' 언어 모델의 성능이 좋다는 것을 의미한다는 점입니다.\n",
    "\n",
    "PPL은 단어의 수로 정규화(normalization) 된 테스트 데이터에 대한 확률의 역수입니다. PPL을 최소화한다는 것은 문장의 확률을 최대화하는 것과 같습니다. 문장 W의 길이가 N이라고 하였을 때의 PPL은 다음과 같습니다.\n",
    "\n",
    "PPL(W)=P(w1,w2,w3,...,wN)−1N=1P(w1,w2,w3,...,wN)−−−−−−−−−−−−−−−−−−√N\n",
    "문장의 확률에 체인룰(chain rule)을 적용하면 아래와 같습니다.\n",
    "\n",
    "PPL(W)=1P(w1,w2,w3,...,wN)−−−−−−−−−−−−−−−−−−√N=1∏Ni=1P(wi|w1,w2,...,wi−1)−−−−−−−−−−−−−−−−−−−−−−√N\n",
    "여기에 n-gram을 적용해볼 수도 있습니다. 예를 들어 bigram 언어 모델의 경우에는 식이 아래와 같습니다.\n",
    "\n",
    "PPL(W)=1∏Ni=1P(wi|wi−1)−−−−−−−−−−−−−−√N\n",
    "\n",
    "\n",
    "\n",
    "reference :https://wikidocs.net/21697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 37s\n",
      "\tTrain Loss: 3.958 | Train PPL:  52.369\n",
      "\t Val. Loss: 4.486 |  Val. PPL:  88.736\n",
      "Epoch: 02 | Time: 0m 36s\n",
      "\tTrain Loss: 3.797 | Train PPL:  44.581\n",
      "\t Val. Loss: 4.303 |  Val. PPL:  73.954\n",
      "Epoch: 03 | Time: 0m 37s\n",
      "\tTrain Loss: 3.632 | Train PPL:  37.791\n",
      "\t Val. Loss: 4.209 |  Val. PPL:  67.260\n",
      "Epoch: 04 | Time: 0m 37s\n",
      "\tTrain Loss: 3.504 | Train PPL:  33.248\n",
      "\t Val. Loss: 4.099 |  Val. PPL:  60.286\n",
      "Epoch: 05 | Time: 0m 36s\n",
      "\tTrain Loss: 3.345 | Train PPL:  28.369\n",
      "\t Val. Loss: 4.055 |  Val. PPL:  57.696\n",
      "Epoch: 06 | Time: 0m 37s\n",
      "\tTrain Loss: 3.218 | Train PPL:  24.984\n",
      "\t Val. Loss: 3.952 |  Val. PPL:  52.062\n",
      "Epoch: 07 | Time: 0m 37s\n",
      "\tTrain Loss: 3.092 | Train PPL:  22.014\n",
      "\t Val. Loss: 3.905 |  Val. PPL:  49.663\n",
      "Epoch: 08 | Time: 0m 37s\n",
      "\tTrain Loss: 2.992 | Train PPL:  19.922\n",
      "\t Val. Loss: 3.789 |  Val. PPL:  44.223\n",
      "Epoch: 09 | Time: 0m 37s\n",
      "\tTrain Loss: 2.881 | Train PPL:  17.838\n",
      "\t Val. Loss: 3.828 |  Val. PPL:  45.980\n",
      "Epoch: 10 | Time: 0m 37s\n",
      "\tTrain Loss: 2.798 | Train PPL:  16.419\n",
      "\t Val. Loss: 3.789 |  Val. PPL:  44.201\n",
      "Epoch: 11 | Time: 0m 37s\n",
      "\tTrain Loss: 2.701 | Train PPL:  14.895\n",
      "\t Val. Loss: 3.778 |  Val. PPL:  43.731\n",
      "Epoch: 12 | Time: 0m 37s\n",
      "\tTrain Loss: 2.630 | Train PPL:  13.868\n",
      "\t Val. Loss: 3.750 |  Val. PPL:  42.527\n",
      "Epoch: 13 | Time: 0m 37s\n",
      "\tTrain Loss: 2.560 | Train PPL:  12.938\n",
      "\t Val. Loss: 3.727 |  Val. PPL:  41.543\n",
      "Epoch: 14 | Time: 0m 38s\n",
      "\tTrain Loss: 2.471 | Train PPL:  11.831\n",
      "\t Val. Loss: 3.717 |  Val. PPL:  41.159\n",
      "Epoch: 15 | Time: 0m 37s\n",
      "\tTrain Loss: 2.412 | Train PPL:  11.160\n",
      "\t Val. Loss: 3.695 |  Val. PPL:  40.258\n",
      "Epoch: 16 | Time: 0m 37s\n",
      "\tTrain Loss: 2.332 | Train PPL:  10.297\n",
      "\t Val. Loss: 3.664 |  Val. PPL:  39.011\n",
      "Epoch: 17 | Time: 0m 37s\n",
      "\tTrain Loss: 2.258 | Train PPL:   9.567\n",
      "\t Val. Loss: 3.782 |  Val. PPL:  43.883\n",
      "Epoch: 18 | Time: 0m 36s\n",
      "\tTrain Loss: 2.188 | Train PPL:   8.915\n",
      "\t Val. Loss: 3.718 |  Val. PPL:  41.176\n",
      "Epoch: 19 | Time: 0m 37s\n",
      "\tTrain Loss: 2.152 | Train PPL:   8.604\n",
      "\t Val. Loss: 3.714 |  Val. PPL:  41.016\n",
      "Epoch: 20 | Time: 0m 37s\n",
      "\tTrain Loss: 2.066 | Train PPL:   7.897\n",
      "\t Val. Loss: 3.709 |  Val. PPL:  40.815\n",
      "Epoch: 21 | Time: 0m 37s\n",
      "\tTrain Loss: 2.026 | Train PPL:   7.587\n",
      "\t Val. Loss: 3.739 |  Val. PPL:  42.046\n",
      "Epoch: 22 | Time: 0m 36s\n",
      "\tTrain Loss: 1.975 | Train PPL:   7.207\n",
      "\t Val. Loss: 3.753 |  Val. PPL:  42.666\n",
      "Epoch: 23 | Time: 0m 37s\n",
      "\tTrain Loss: 1.921 | Train PPL:   6.825\n",
      "\t Val. Loss: 3.754 |  Val. PPL:  42.707\n",
      "Epoch: 24 | Time: 0m 37s\n",
      "\tTrain Loss: 1.863 | Train PPL:   6.445\n",
      "\t Val. Loss: 3.795 |  Val. PPL:  44.499\n",
      "Epoch: 25 | Time: 0m 37s\n",
      "\tTrain Loss: 1.804 | Train PPL:   6.071\n",
      "\t Val. Loss: 3.826 |  Val. PPL:  45.870\n",
      "Epoch: 26 | Time: 0m 37s\n",
      "\tTrain Loss: 1.773 | Train PPL:   5.891\n",
      "\t Val. Loss: 3.808 |  Val. PPL:  45.056\n",
      "Epoch: 27 | Time: 0m 37s\n",
      "\tTrain Loss: 1.690 | Train PPL:   5.421\n",
      "\t Val. Loss: 3.845 |  Val. PPL:  46.765\n",
      "Epoch: 28 | Time: 0m 37s\n",
      "\tTrain Loss: 1.674 | Train PPL:   5.334\n",
      "\t Val. Loss: 3.836 |  Val. PPL:  46.318\n",
      "Epoch: 29 | Time: 0m 37s\n",
      "\tTrain Loss: 1.633 | Train PPL:   5.119\n",
      "\t Val. Loss: 3.886 |  Val. PPL:  48.730\n",
      "Epoch: 30 | Time: 0m 37s\n",
      "\tTrain Loss: 1.589 | Train PPL:   4.898\n",
      "\t Val. Loss: 3.923 |  Val. PPL:  50.537\n",
      "Epoch: 31 | Time: 0m 37s\n",
      "\tTrain Loss: 1.553 | Train PPL:   4.726\n",
      "\t Val. Loss: 3.963 |  Val. PPL:  52.639\n",
      "Epoch: 32 | Time: 0m 37s\n",
      "\tTrain Loss: 1.520 | Train PPL:   4.573\n",
      "\t Val. Loss: 3.957 |  Val. PPL:  52.282\n",
      "Epoch: 33 | Time: 0m 37s\n",
      "\tTrain Loss: 1.461 | Train PPL:   4.311\n",
      "\t Val. Loss: 4.012 |  Val. PPL:  55.267\n",
      "Epoch: 34 | Time: 0m 37s\n",
      "\tTrain Loss: 1.436 | Train PPL:   4.203\n",
      "\t Val. Loss: 4.024 |  Val. PPL:  55.933\n",
      "Epoch: 35 | Time: 0m 37s\n",
      "\tTrain Loss: 1.398 | Train PPL:   4.046\n",
      "\t Val. Loss: 4.052 |  Val. PPL:  57.516\n",
      "Epoch: 36 | Time: 0m 37s\n",
      "\tTrain Loss: 1.351 | Train PPL:   3.863\n",
      "\t Val. Loss: 4.104 |  Val. PPL:  60.570\n",
      "Epoch: 37 | Time: 0m 38s\n",
      "\tTrain Loss: 1.319 | Train PPL:   3.739\n",
      "\t Val. Loss: 4.113 |  Val. PPL:  61.133\n",
      "Epoch: 38 | Time: 0m 37s\n",
      "\tTrain Loss: 1.290 | Train PPL:   3.632\n",
      "\t Val. Loss: 4.166 |  Val. PPL:  64.434\n",
      "Epoch: 39 | Time: 0m 37s\n",
      "\tTrain Loss: 1.266 | Train PPL:   3.546\n",
      "\t Val. Loss: 4.098 |  Val. PPL:  60.249\n",
      "Epoch: 40 | Time: 0m 37s\n",
      "\tTrain Loss: 1.225 | Train PPL:   3.404\n",
      "\t Val. Loss: 4.221 |  Val. PPL:  68.106\n",
      "Epoch: 41 | Time: 0m 37s\n",
      "\tTrain Loss: 1.223 | Train PPL:   3.399\n",
      "\t Val. Loss: 4.206 |  Val. PPL:  67.068\n",
      "Epoch: 42 | Time: 0m 37s\n",
      "\tTrain Loss: 1.192 | Train PPL:   3.294\n",
      "\t Val. Loss: 4.170 |  Val. PPL:  64.744\n",
      "Epoch: 43 | Time: 0m 37s\n",
      "\tTrain Loss: 1.147 | Train PPL:   3.148\n",
      "\t Val. Loss: 4.279 |  Val. PPL:  72.194\n",
      "Epoch: 44 | Time: 0m 37s\n",
      "\tTrain Loss: 1.124 | Train PPL:   3.078\n",
      "\t Val. Loss: 4.253 |  Val. PPL:  70.307\n",
      "Epoch: 45 | Time: 0m 37s\n",
      "\tTrain Loss: 1.109 | Train PPL:   3.031\n",
      "\t Val. Loss: 4.325 |  Val. PPL:  75.546\n",
      "Epoch: 46 | Time: 0m 37s\n",
      "\tTrain Loss: 1.075 | Train PPL:   2.929\n",
      "\t Val. Loss: 4.372 |  Val. PPL:  79.207\n",
      "Epoch: 47 | Time: 0m 37s\n",
      "\tTrain Loss: 1.049 | Train PPL:   2.853\n",
      "\t Val. Loss: 4.393 |  Val. PPL:  80.870\n",
      "Epoch: 48 | Time: 0m 37s\n",
      "\tTrain Loss: 1.024 | Train PPL:   2.783\n",
      "\t Val. Loss: 4.399 |  Val. PPL:  81.350\n",
      "Epoch: 49 | Time: 0m 37s\n",
      "\tTrain Loss: 1.013 | Train PPL:   2.755\n",
      "\t Val. Loss: 4.458 |  Val. PPL:  86.323\n",
      "Epoch: 50 | Time: 0m 37s\n",
      "\tTrain Loss: 0.999 | Train PPL:   2.714\n",
      "\t Val. Loss: 4.431 |  Val. PPL:  84.048\n",
      "Epoch: 51 | Time: 0m 37s\n",
      "\tTrain Loss: 0.955 | Train PPL:   2.598\n",
      "\t Val. Loss: 4.461 |  Val. PPL:  86.586\n",
      "Epoch: 52 | Time: 0m 37s\n",
      "\tTrain Loss: 0.934 | Train PPL:   2.544\n",
      "\t Val. Loss: 4.539 |  Val. PPL:  93.556\n",
      "Epoch: 53 | Time: 0m 37s\n",
      "\tTrain Loss: 0.922 | Train PPL:   2.515\n",
      "\t Val. Loss: 4.552 |  Val. PPL:  94.867\n",
      "Epoch: 54 | Time: 0m 38s\n",
      "\tTrain Loss: 0.898 | Train PPL:   2.456\n",
      "\t Val. Loss: 4.587 |  Val. PPL:  98.235\n",
      "Epoch: 55 | Time: 0m 37s\n",
      "\tTrain Loss: 0.860 | Train PPL:   2.364\n",
      "\t Val. Loss: 4.610 |  Val. PPL: 100.513\n",
      "Epoch: 56 | Time: 0m 37s\n",
      "\tTrain Loss: 0.852 | Train PPL:   2.345\n",
      "\t Val. Loss: 4.622 |  Val. PPL: 101.697\n",
      "Epoch: 57 | Time: 0m 37s\n",
      "\tTrain Loss: 0.829 | Train PPL:   2.291\n",
      "\t Val. Loss: 4.633 |  Val. PPL: 102.837\n",
      "Epoch: 58 | Time: 0m 37s\n",
      "\tTrain Loss: 0.807 | Train PPL:   2.240\n",
      "\t Val. Loss: 4.673 |  Val. PPL: 107.063\n",
      "Epoch: 59 | Time: 0m 37s\n",
      "\tTrain Loss: 0.811 | Train PPL:   2.249\n",
      "\t Val. Loss: 4.681 |  Val. PPL: 107.867\n",
      "Epoch: 60 | Time: 0m 38s\n",
      "\tTrain Loss: 0.770 | Train PPL:   2.161\n",
      "\t Val. Loss: 4.769 |  Val. PPL: 117.821\n",
      "Epoch: 61 | Time: 0m 37s\n",
      "\tTrain Loss: 0.767 | Train PPL:   2.153\n",
      "\t Val. Loss: 4.763 |  Val. PPL: 117.096\n",
      "Epoch: 62 | Time: 0m 37s\n",
      "\tTrain Loss: 0.746 | Train PPL:   2.110\n",
      "\t Val. Loss: 4.769 |  Val. PPL: 117.822\n",
      "Epoch: 63 | Time: 0m 37s\n",
      "\tTrain Loss: 0.744 | Train PPL:   2.104\n",
      "\t Val. Loss: 4.883 |  Val. PPL: 132.092\n",
      "Epoch: 64 | Time: 0m 37s\n",
      "\tTrain Loss: 0.723 | Train PPL:   2.061\n",
      "\t Val. Loss: 4.840 |  Val. PPL: 126.522\n",
      "Epoch: 65 | Time: 0m 37s\n",
      "\tTrain Loss: 0.706 | Train PPL:   2.027\n",
      "\t Val. Loss: 4.878 |  Val. PPL: 131.411\n",
      "Epoch: 66 | Time: 0m 37s\n",
      "\tTrain Loss: 0.684 | Train PPL:   1.982\n",
      "\t Val. Loss: 4.925 |  Val. PPL: 137.652\n",
      "Epoch: 67 | Time: 0m 38s\n",
      "\tTrain Loss: 0.682 | Train PPL:   1.979\n",
      "\t Val. Loss: 4.967 |  Val. PPL: 143.634\n",
      "Epoch: 68 | Time: 0m 37s\n",
      "\tTrain Loss: 0.663 | Train PPL:   1.940\n",
      "\t Val. Loss: 4.950 |  Val. PPL: 141.144\n",
      "Epoch: 69 | Time: 0m 37s\n",
      "\tTrain Loss: 0.640 | Train PPL:   1.896\n",
      "\t Val. Loss: 5.046 |  Val. PPL: 155.381\n",
      "Epoch: 70 | Time: 0m 37s\n",
      "\tTrain Loss: 0.632 | Train PPL:   1.881\n",
      "\t Val. Loss: 5.044 |  Val. PPL: 155.058\n",
      "Epoch: 71 | Time: 0m 37s\n",
      "\tTrain Loss: 0.636 | Train PPL:   1.889\n",
      "\t Val. Loss: 5.077 |  Val. PPL: 160.233\n",
      "Epoch: 72 | Time: 0m 38s\n",
      "\tTrain Loss: 0.625 | Train PPL:   1.869\n",
      "\t Val. Loss: 5.065 |  Val. PPL: 158.440\n",
      "Epoch: 73 | Time: 0m 38s\n",
      "\tTrain Loss: 0.602 | Train PPL:   1.827\n",
      "\t Val. Loss: 5.107 |  Val. PPL: 165.218\n",
      "Epoch: 74 | Time: 0m 37s\n",
      "\tTrain Loss: 0.589 | Train PPL:   1.802\n",
      "\t Val. Loss: 5.115 |  Val. PPL: 166.488\n",
      "Epoch: 75 | Time: 0m 38s\n",
      "\tTrain Loss: 0.580 | Train PPL:   1.786\n",
      "\t Val. Loss: 5.143 |  Val. PPL: 171.258\n",
      "Epoch: 76 | Time: 0m 38s\n",
      "\tTrain Loss: 0.572 | Train PPL:   1.773\n",
      "\t Val. Loss: 5.170 |  Val. PPL: 175.925\n",
      "Epoch: 77 | Time: 0m 37s\n",
      "\tTrain Loss: 0.563 | Train PPL:   1.756\n",
      "\t Val. Loss: 5.181 |  Val. PPL: 177.824\n",
      "Epoch: 78 | Time: 0m 37s\n",
      "\tTrain Loss: 0.550 | Train PPL:   1.733\n",
      "\t Val. Loss: 5.244 |  Val. PPL: 189.351\n",
      "Epoch: 79 | Time: 0m 37s\n",
      "\tTrain Loss: 0.533 | Train PPL:   1.705\n",
      "\t Val. Loss: 5.262 |  Val. PPL: 192.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Time: 0m 38s\n",
      "\tTrain Loss: 0.528 | Train PPL:   1.696\n",
      "\t Val. Loss: 5.235 |  Val. PPL: 187.746\n",
      "Epoch: 81 | Time: 0m 38s\n",
      "\tTrain Loss: 0.522 | Train PPL:   1.686\n",
      "\t Val. Loss: 5.314 |  Val. PPL: 203.131\n",
      "Epoch: 82 | Time: 0m 37s\n",
      "\tTrain Loss: 0.518 | Train PPL:   1.679\n",
      "\t Val. Loss: 5.312 |  Val. PPL: 202.746\n",
      "Epoch: 83 | Time: 0m 37s\n",
      "\tTrain Loss: 0.502 | Train PPL:   1.652\n",
      "\t Val. Loss: 5.396 |  Val. PPL: 220.416\n",
      "Epoch: 84 | Time: 0m 37s\n",
      "\tTrain Loss: 0.507 | Train PPL:   1.660\n",
      "\t Val. Loss: 5.360 |  Val. PPL: 212.724\n",
      "Epoch: 85 | Time: 0m 37s\n",
      "\tTrain Loss: 0.482 | Train PPL:   1.619\n",
      "\t Val. Loss: 5.403 |  Val. PPL: 222.096\n",
      "Epoch: 86 | Time: 0m 37s\n",
      "\tTrain Loss: 0.481 | Train PPL:   1.617\n",
      "\t Val. Loss: 5.434 |  Val. PPL: 229.135\n",
      "Epoch: 87 | Time: 0m 38s\n",
      "\tTrain Loss: 0.476 | Train PPL:   1.609\n",
      "\t Val. Loss: 5.473 |  Val. PPL: 238.085\n",
      "Epoch: 88 | Time: 0m 38s\n",
      "\tTrain Loss: 0.476 | Train PPL:   1.610\n",
      "\t Val. Loss: 5.436 |  Val. PPL: 229.504\n",
      "Epoch: 89 | Time: 0m 37s\n",
      "\tTrain Loss: 0.454 | Train PPL:   1.575\n",
      "\t Val. Loss: 5.544 |  Val. PPL: 255.613\n",
      "Epoch: 90 | Time: 0m 37s\n",
      "\tTrain Loss: 0.453 | Train PPL:   1.573\n",
      "\t Val. Loss: 5.525 |  Val. PPL: 250.773\n",
      "Epoch: 91 | Time: 0m 37s\n",
      "\tTrain Loss: 0.450 | Train PPL:   1.569\n",
      "\t Val. Loss: 5.537 |  Val. PPL: 253.984\n",
      "Epoch: 92 | Time: 0m 37s\n",
      "\tTrain Loss: 0.438 | Train PPL:   1.550\n",
      "\t Val. Loss: 5.518 |  Val. PPL: 249.174\n",
      "Epoch: 93 | Time: 0m 38s\n",
      "\tTrain Loss: 0.430 | Train PPL:   1.538\n",
      "\t Val. Loss: 5.609 |  Val. PPL: 272.943\n",
      "Epoch: 94 | Time: 0m 37s\n",
      "\tTrain Loss: 0.415 | Train PPL:   1.514\n",
      "\t Val. Loss: 5.591 |  Val. PPL: 268.043\n",
      "Epoch: 95 | Time: 0m 37s\n",
      "\tTrain Loss: 0.404 | Train PPL:   1.498\n",
      "\t Val. Loss: 5.691 |  Val. PPL: 296.336\n",
      "Epoch: 96 | Time: 0m 37s\n",
      "\tTrain Loss: 0.413 | Train PPL:   1.512\n",
      "\t Val. Loss: 5.652 |  Val. PPL: 284.895\n",
      "Epoch: 97 | Time: 0m 37s\n",
      "\tTrain Loss: 0.411 | Train PPL:   1.508\n",
      "\t Val. Loss: 5.613 |  Val. PPL: 273.848\n",
      "Epoch: 98 | Time: 0m 37s\n",
      "\tTrain Loss: 0.405 | Train PPL:   1.499\n",
      "\t Val. Loss: 5.632 |  Val. PPL: 279.190\n",
      "Epoch: 99 | Time: 0m 37s\n",
      "\tTrain Loss: 0.413 | Train PPL:   1.511\n",
      "\t Val. Loss: 5.718 |  Val. PPL: 304.298\n",
      "Epoch: 100 | Time: 0m 37s\n",
      "\tTrain Loss: 0.385 | Train PPL:   1.469\n",
      "\t Val. Loss: 5.766 |  Val. PPL: 319.161\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.657 | Test PPL:  38.735 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
